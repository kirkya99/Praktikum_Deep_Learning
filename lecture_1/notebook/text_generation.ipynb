{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:13.822929Z",
     "start_time": "2025-04-11T06:42:13.820932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from time import time"
   ],
   "id": "a8ad13f5a11aac5b",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load the Shakespeare text file / Setup Tokenizer",
   "id": "5fd6046214a7769"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:13.843165Z",
     "start_time": "2025-04-11T06:42:13.838591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "path_to_file = keras.utils.get_file(\n",
    "    'shakespeare.txt',\n",
    "    'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    ")\n",
    "print(path_to_file)\n",
    "\n",
    "with open(path_to_file) as f:\n",
    "    shakespeare_text = f.read()\n",
    "print(shakespeare_text[:148])\n",
    "\n",
    "shakespeare_tensor = tf.constant([shakespeare_text])"
   ],
   "id": "4d1771a4412ee4ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/.keras/datasets/shakespeare.txt\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:13.871692Z",
     "start_time": "2025-04-11T06:42:13.862151Z"
    }
   },
   "cell_type": "code",
   "source": "set(shakespeare_text)",
   "id": "2e9d330f42652e52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '3',\n",
       " ':',\n",
       " ';',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:13.905115Z",
     "start_time": "2025-04-11T06:42:13.895478Z"
    }
   },
   "cell_type": "code",
   "source": "len(set(shakespeare_text.lower().strip()))",
   "id": "f183ad121c8bc3fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:13.939020Z",
     "start_time": "2025-04-11T06:42:13.930708Z"
    }
   },
   "cell_type": "code",
   "source": "vocab = list(set(shakespeare_text.lower().strip()))",
   "id": "8725c428ca01db50",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.386034Z",
     "start_time": "2025-04-11T06:42:13.971150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True, lower=True)\n",
    "tokenizer.fit_on_texts(shakespeare_text.lower())\n",
    "config = tokenizer.get_config()\n",
    "tokenizer.texts_to_sequences([\"hello\", \"world\"])"
   ],
   "id": "d7789205ef26bed1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 2, 12, 12, 4], [17, 4, 9, 12, 13]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.412364Z",
     "start_time": "2025-04-11T06:42:14.410462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_tokens = len(tokenizer.word_index)\n",
    "dataset_size = tokenizer.document_count"
   ],
   "id": "cff1df332f8830b7",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.499735Z",
     "start_time": "2025-04-11T06:42:14.431828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text]))\n",
    "print(f\"{encoded[:10]}\")"
   ],
   "id": "50883cd67f1f0a03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20  6  9  8  3  1 19  6  3  6]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Dataset",
   "id": "3ef9fb4d1f2f6f74"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.536514Z",
     "start_time": "2025-04-11T06:42:14.534496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = dataset_size * 90 // 100\n",
    "print(f\"train_size = {train_size:,}\")"
   ],
   "id": "8c385425b62097d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 1,003,854\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.601639Z",
     "start_time": "2025-04-11T06:42:14.579727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(encoded)\n",
    "#dataset = dataset.repeat()\n",
    "n_steps = 50\n",
    "dataset = dataset.window(n_steps + 1, shift=1, drop_remainder=True)\n",
    "dataset = dataset.flat_map(lambda window_ds: window_ds.batch(n_steps + 1))"
   ],
   "id": "3200759e7503fb41",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.632993Z",
     "start_time": "2025-04-11T06:42:14.620524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x in dataset.take(2):\n",
    "    print(x)"
   ],
   "id": "f18831d293d69e9d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[20  6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2\n",
      "  1 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2\n",
      "  5  9  1], shape=(51,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[ 6  9  8  3  1 19  6  3  6 36  2 10 24 11 22  2 20  4  9  2  1 17  2  1\n",
      " 23  9  4 19  2  2 13  1  5 10 16  1 20 14  9  3  7  2  9 18  1  7  2  5\n",
      "  9  1 15], shape=(51,), dtype=int64)\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.656337Z",
     "start_time": "2025-04-11T06:42:14.653137Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.batch(128)",
   "id": "33d7252a8c929525",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.695804Z",
     "start_time": "2025-04-11T06:42:14.676362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x in dataset.take(1):\n",
    "    print(x.shape)"
   ],
   "id": "38988425d67b0b90",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 51)\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.726389Z",
     "start_time": "2025-04-11T06:42:14.716256Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.map(lambda window: (window[:, :-1], window[:, 1:]))",
   "id": "7a7bb314c200422c",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.754410Z",
     "start_time": "2025-04-11T06:42:14.749881Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = dataset.cache().prefetch(tf.data.AUTOTUNE)",
   "id": "b775c4c2bff70c35",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:42:14.865435Z",
     "start_time": "2025-04-11T06:42:14.777084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x, y in dataset.take(1):\n",
    "    print(f\"x = {x.shape}\")\n",
    "    print(f\"y = {y.shape}\")"
   ],
   "id": "dbb18e77bb8b3256",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = (128, 50)\n",
      "y = (128, 50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-11 06:42:14.807430: W tensorflow/core/kernels/data/cache_dataset_ops.cc:916] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Models",
   "id": "dcd4f6e24384924b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:46:04.449791Z",
     "start_time": "2025-04-11T06:46:04.407370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "m1 = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Input(shape=(None, n_tokens)),\n",
    "        keras.layers.GRU(128, return_sequences=True),\n",
    "        keras.layers.Dense(n_tokens, activation=\"softmax\")\n",
    "    ],\n",
    ")\n",
    "m1.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
    "m1.summary()\n",
    "model = m1"
   ],
   "id": "77f28cb295068a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_3\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_3 (\u001B[38;5;33mGRU\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │        \u001B[38;5;34m64,896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m39\u001B[0m)       │         \u001B[38;5;34m5,031\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">64,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,031</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m69,927\u001B[0m (273.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,927</span> (273.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m69,927\u001B[0m (273.15 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">69,927</span> (273.15 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T06:46:05.671973Z",
     "start_time": "2025-04-11T06:46:05.577496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"to be \"\n",
    "tokens = tokenizer.texts_to_sequences([text])\n",
    "inp_tf = tf.constant(tokens)\n",
    "inp_tf = tf.one_hot(inp_tf, depth=n_tokens)\n",
    "print(inp_tf.shape)\n",
    "y = model.predict(inp_tf)\n",
    "print(y.shape)\n",
    "y = tf.argmax(y[0,-1])"
   ],
   "id": "6dadbf98f6e01ed8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6, 39)\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "(1, 6, 39)\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:35:09.096937Z",
     "start_time": "2025-04-11T07:35:08.841997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)\n",
    "history = m1.fit(dataset, epochs=10, steps_per_epoch=train_size // 128, callbacks=[early_stopping], verbose=2)\n",
    "m1.save(\"models/shakespeare_gru_1.keras\")"
   ],
   "id": "10c4b12974da1530",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001B[1mInvalid input shape for input Tensor(\"sequential_3_1/Cast:0\", shape=(None, None), dtype=float32). Expected shape (None, None, 39), but input has incompatible shape (None, None)\u001B[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n  • training=True\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[82]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m early_stopping = keras.callbacks.EarlyStopping(monitor=\u001B[33m\"\u001B[39m\u001B[33mloss\u001B[39m\u001B[33m\"\u001B[39m, min_delta=\u001B[32m0.002\u001B[39m, patience=\u001B[32m2\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m history = \u001B[43mm1\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain_size\u001B[49m\u001B[43m \u001B[49m\u001B[43m/\u001B[49m\u001B[43m/\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      3\u001B[39m m1.save(\u001B[33m\"\u001B[39m\u001B[33mmodels/shakespeare_gru_1.keras\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py:122\u001B[39m, in \u001B[36mfilter_traceback.<locals>.error_handler\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    119\u001B[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001B[32m    120\u001B[39m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[32m    121\u001B[39m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m122\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m e.with_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    124\u001B[39m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:273\u001B[39m, in \u001B[36mFunctional._adjust_input_rank\u001B[39m\u001B[34m(self, flat_inputs)\u001B[39m\n\u001B[32m    271\u001B[39m             adjusted.append(ops.expand_dims(x, axis=-\u001B[32m1\u001B[39m))\n\u001B[32m    272\u001B[39m             \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m273\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    274\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mInvalid input shape for input \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m. Expected shape \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    275\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mref_shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, but input has incompatible shape \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mx.shape\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    276\u001B[39m     )\n\u001B[32m    277\u001B[39m \u001B[38;5;66;03m# Add back metadata.\u001B[39;00m\n\u001B[32m    278\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(flat_inputs)):\n",
      "\u001B[31mValueError\u001B[39m: Exception encountered when calling Sequential.call().\n\n\u001B[1mInvalid input shape for input Tensor(\"sequential_3_1/Cast:0\", shape=(None, None), dtype=float32). Expected shape (None, None, 39), but input has incompatible shape (None, None)\u001B[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, None), dtype=int64)\n  • training=True\n  • mask=None"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a45e5195f058949f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
