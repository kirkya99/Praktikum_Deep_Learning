{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d58c621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 20:11:10.596184: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-02 20:11:10.603516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748895070.612141     632 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748895070.614653     632 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-02 20:11:10.623734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# from notebooks.prepare.mnist_exercises import early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ae732f",
   "metadata": {},
   "source": [
    "## Daten laden und aufbereiten\n",
    "Quelle: https://www.kaggle.com/datasets/abhi8923shriv/sentiment-analysis-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d2f9191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27481 entries, 0 to 27480\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   textID            27481 non-null  object \n",
      " 1   text              27480 non-null  object \n",
      " 2   selected_text     27480 non-null  object \n",
      " 3   sentiment         27481 non-null  object \n",
      " 4   Time of Tweet     27481 non-null  object \n",
      " 5   Age of User       27481 non-null  object \n",
      " 6   Country           27481 non-null  object \n",
      " 7   Population -2020  27481 non-null  int64  \n",
      " 8   Land Area (Km�)   27481 non-null  float64\n",
      " 9   Density (P/Km�)   27481 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('kaggle_sentiment/tweet_sentiment_train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "543629ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>Age of User</th>\n",
       "      <th>Country</th>\n",
       "      <th>Population -2020</th>\n",
       "      <th>Land Area (Km�)</th>\n",
       "      <th>Density (P/Km�)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>morning</td>\n",
       "      <td>0-20</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>38928346</td>\n",
       "      <td>652860.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>noon</td>\n",
       "      <td>21-30</td>\n",
       "      <td>Albania</td>\n",
       "      <td>2877797</td>\n",
       "      <td>27400.0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>night</td>\n",
       "      <td>31-45</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>43851044</td>\n",
       "      <td>2381740.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                            text  \\\n",
       "0  cb774db0d1             I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                       my boss is bullying me...   \n",
       "\n",
       "                         selected_text sentiment Time of Tweet Age of User  \\\n",
       "0  I`d have responded, if I were going   neutral       morning        0-20   \n",
       "1                             Sooo SAD  negative          noon       21-30   \n",
       "2                          bullying me  negative         night       31-45   \n",
       "\n",
       "       Country  Population -2020  Land Area (Km�)  Density (P/Km�)  \n",
       "0  Afghanistan          38928346         652860.0               60  \n",
       "1      Albania           2877797          27400.0              105  \n",
       "2      Algeria          43851044        2381740.0               18  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea290ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def custom_standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
    "    return tf.strings.regex_replace(\n",
    "            stripped_html,\n",
    "            '[%s]' % re.escape(string.punctuation),\n",
    "            ''\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "349e9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e7d1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_632/1026471518.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'] = df['sentiment'].replace(sentiment_mapping)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Soooo high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Both of you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                I`d have responded, if I were going          0\n",
       "1      Sooo SAD I will miss you here in San Diego!!!          2\n",
       "2                          my boss is bullying me...          2\n",
       "3                     what interview! leave me alone          2\n",
       "4   Sons of ****, why couldn`t they put them on t...          2\n",
       "5  http://www.dothebouncy.com/smf - some shameles...          0\n",
       "6  2am feedings for the baby are fun when he is a...          1\n",
       "7                                         Soooo high          0\n",
       "8                                        Both of you          0\n",
       "9   Journey!? Wow... u just became cooler.  hehe....          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_mapping = {'negative': 2, 'neutral': 0, 'positive': 1}\n",
    "df['sentiment'] = df['sentiment'].replace(sentiment_mapping)\n",
    "df[['text', 'sentiment']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20c23e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1748895072.163693     632 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9305 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m labels = df[\u001b[33m'\u001b[39m\u001b[33msentiment\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m dataset = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:827\u001b[39m, in \u001b[36mDatasetV2.from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[39m, in \u001b[36m_from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensor_slices\u001b[39m(tensors, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:53\u001b[39m, in \u001b[36m_TensorSliceDataset.__init__\u001b[39m\u001b[34m(self, element, is_files, name)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tensors[\u001b[32m1\u001b[39m:]:\n\u001b[32m     45\u001b[39m   batch_dim.assert_is_compatible_with(\n\u001b[32m     46\u001b[39m       tensor_shape.Dimension(\n\u001b[32m     47\u001b[39m           tensor_shape.dimension_value(t.get_shape()[\u001b[32m0\u001b[39m])))\n\u001b[32m     49\u001b[39m variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m._tensors,\n\u001b[32m     51\u001b[39m     output_shapes=structure.get_flat_tensor_shapes(\u001b[38;5;28mself\u001b[39m._structure),\n\u001b[32m     52\u001b[39m     is_files=is_files,\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     metadata=\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_metadata\u001b[49m.SerializeToString())\n\u001b[32m     54\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(variant_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:671\u001b[39m, in \u001b[36mDatasetV2._metadata\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Helper for generating dataset metadata.\"\"\"\u001b[39;00m\n\u001b[32m    670\u001b[39m metadata = dataset_metadata_pb2.Metadata()\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._name:\n\u001b[32m    672\u001b[39m   metadata.name = _validate_and_encode(\u001b[38;5;28mself\u001b[39m._name)\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadata\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "texts = df['text'].values\n",
    "labels = df['sentiment'].values\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices(texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59f6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda x, y: ((custom_standardization(x), y)))\n",
    "for text, label in dataset.take(2):\n",
    "    print(text.numpy())\n",
    "    print(label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e53e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 22_000\n",
    "val_size = 2_000\n",
    "test_size = len(df) - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(train_size + val_size)\n",
    "train_ds = dataset.take(train_size)\n",
    "val_ds = dataset.skip(train_size).take(val_size)\n",
    "test_ds = dataset.skip(train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1a3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(128).cache().prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.batch(128).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 0\n",
    "for text, label in dataset:\n",
    "    if len(text.numpy()) > max_sequence_length:\n",
    "        max_sequence_length = len(text.numpy())\n",
    "print(max_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_hub\n",
    "\n",
    "bert_name = \"bert_tiny_en_uncased\"\n",
    "classifier = keras_hub.models.TextClassifier.from_preset(bert_name, sequence_lengths=256, num_classes=3)\n",
    "classifier.build(input_shape=(None, 256))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=2,\n",
    "        min_delta=0.02,\n",
    "        restore_best_weights=True\n",
    "        )\n",
    "classifier.fit(train_ds, epochs=5, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3234bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.evaluate(test_ds.batch(16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37ddaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras_hub\n",
    "\n",
    "bert_name = \"bert_tiny_en_uncased\"\n",
    "preprocess_layer = keras_hub.models.BertPreprocessor.from_preset(bert_name, trainable=False)\n",
    "backbone = keras_hub.models.Backbone.from_preset(bert_name, trainable=False)\n",
    "#tokenizer = keras_nlp.models.Tokenizer.from_preset(bert_name)\n",
    "\n",
    "text_input = keras.Input(shape=(), dtype=tf.string, name='text')\n",
    "outputs = backbone(preprocess_layer(text_input))\n",
    "net = outputs['pooled_output'][:, :]\n",
    "net = keras.layers.Flatten()(net)\n",
    "net = keras.layers.Dropout(0.1)(net)\n",
    "net = keras.layers.Dense(512, activation='relu')(net)\n",
    "net = keras.layers.Dense(3, activation='softmax')(net)\n",
    "model = keras.Model(text_input, net, name='bert_sentiment_model_1')\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=\"adam\", loss=loss_fn, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "Die Ergebnisse sind nicht besonders gut. Wenn im backbone trainable=True gesetzt wird, sind die Ergebnisse deutlich besser (auch weil mehr Parameter trainiert werden können).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf68529",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, epochs=5, validation_data=val_ds, callbacks=[early_stopping_cb], verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
