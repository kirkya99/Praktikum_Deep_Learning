{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ff7c47",
   "metadata": {},
   "source": [
    "# Finale Aufgabe für Praktikum Deep Learning <br>Textgenerierung mit RNN: Modelltraining\n",
    "\n",
    "* **Name:** Fabian Schotte\n",
    "* **Email:** fabian.schotte@rwu.de\n",
    "* **Matrikelnummer:** 35604\n",
    "* **Studiengang:** Angewandte Informatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb461a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from work import models\n",
    "import time \n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc877b",
   "metadata": {},
   "source": [
    "## Vorbereitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b982723",
   "metadata": {},
   "source": [
    "### Laden der Trainingsdaten\n",
    "Hier werden die Trainings- und Testdaten der Kaggle Sentiment Analyis aus deren CSV-Dateien ausgelesen und die Inhalte der Spalte `text` zu dem String `kaggle_text` zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1343b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_test.csv', encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "kaggle_text_train = df_train['text'].str.cat(sep='\\n')\n",
    "kaggle_text_test = df_test['text'].str.cat(sep='\\n')\n",
    "# kaggle_text = kaggle_text_train + '\\n' + kaggle_text_test\n",
    "kaggle_text = kaggle_text_train\n",
    "# kaggle_text = kaggle_text_test\n",
    "\n",
    "print(kaggle_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b972c94",
   "metadata": {},
   "source": [
    "Im nächsten Codeblock wird ein Set der einzigartigen Charaktere im String `kaggle_text` mit dem Namen `vocab` erstellt. Ebenso werden die darin vorhandenen Charaktere ausgegeben und die Länge des Sets ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c7dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(kaggle_text))\n",
    "print(vocab)\n",
    "print(f\"vocab size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ee022",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Im folgenden Codeblock wird ein Beispieltext zu einer Liste von Charakteren aufgeteilt und ausgegeben. Diese List wird als `chars` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21db466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_texts = ['hello world', 'hello world']\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c60104",
   "metadata": {},
   "source": [
    "In der Funktion `ids_from_chars` werden die gegebenen Charaktere in eine zugeordnete Zahl für das Training und die Vorhersage umgewandelt.\n",
    "Die Funktion `chars_from_ids` funktioniert genau umgekehrt, indem hier die gegebenen Zahlen in die dazugehörigen Charaktere umgewandelt werden.\n",
    "Hier werden auch die beiden Methoden für den Beispieltext aus `chars` durchgeführt und ausgegeben. Zur Vollständigkeit werden die Charaktere, die aus den Zahlenwerten generiert wurden, wieder zu einem String zusammengefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6db8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "print(ids)\n",
    "\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)\n",
    "print(chars)\n",
    "\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd5b17",
   "metadata": {},
   "source": [
    "In `text_from_ids(ids)` wird genau die Operation für das Zusammenfügen der Charaktere zu einem String ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae684c0",
   "metadata": {},
   "source": [
    "Hier wird die zuvor genannte Funktion zur Berechnung der Zahlenwerte aus den Charakteren `kaggle_text` verwendet, um die Trainingsdaten als Zahlenwerte zu erhalten. Diese werden in `all_ids` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(kaggle_text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d7080",
   "metadata": {},
   "source": [
    "Als nächstes wird ein Dataset aus den Zahlenwerten generiert. Die ersten 10 Werte des Datasets werden als Charaktere ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99eea65",
   "metadata": {},
   "source": [
    "Mit `seq_lenth` wird die Länge der Sequenz definiert, mit dem die Modelle trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a270a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5169f2",
   "metadata": {},
   "source": [
    "Im nächsten Schritt werden die Sequenzen mit Hilfe von `seq_lenth` generiert. Die Daten für die Sequenzeb kommen aus dem zuvor angelegten Dataset `ids_dataset`.\n",
    "Dazu werden auch die Charaktere der ersten Sequenz zuerst einzeln und dann als Text ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq).numpy())\n",
    "for seq in sequences.take(1):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905968c",
   "metadata": {},
   "source": [
    "In `split_input_target(sequence)` werden die Inputs und Target Labels der Sequenz generiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea2d1b",
   "metadata": {},
   "source": [
    "Im folgenden Code wird die zuvor erstellte Methode `split_input_target` auf die Sequenzen der Kaggle Trainingsdaten angewendet und die Länge des Datasets ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87752867",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_dataset = sequences.map(split_input_target)\n",
    "len(kaggle_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa96a1",
   "metadata": {},
   "source": [
    "Als nächstes werden Beispiele für die Input und Labels als Text und mit dessen Shape ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15082ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example, target_example in kaggle_dataset.take(1):\n",
    "    print(\"Input:\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af338f6",
   "metadata": {},
   "source": [
    "Als nächstes werden folgende Variablen für das Training definiert:\n",
    "- Mit `BATCH_SIZE` wird definiert, wie viele Input-Label-Paare in einer Epoche verarbeitet werden. Hier sind dies 150\n",
    "- Mit `BUFFER_SIZE` wird die Anzahl der Elemente des Datasets definiert, die zufällig gemischt werden, bevor sie in die Batches eingeteilt werden.\n",
    "\n",
    "Dieses Variablen werden hier auch auf das Dataset `kaggle_dataset` angewendet und dieses Dataset wird ebenfalls ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 150\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "kaggle_dataset = (\n",
    "    kaggle_dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "kaggle_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841381c6",
   "metadata": {},
   "source": [
    "### 1. GRU-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e09a3",
   "metadata": {},
   "source": [
    "Hier werden die Variablen für das erste GRU-Modell definiert.\n",
    "`vocab_size_1` wird auf die Anzahl der einzigartigen Zeichen gesetzt und der Vektor für die Embedding-Schicht wird in `embedding_dim_1` auf 256 gesetzt. Die Anzahl der Neuronen wird in `rnn_units` auf 2048 gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_1 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_1 = 256\n",
    "rnn_units_1 = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e067309",
   "metadata": {},
   "source": [
    "Hier wird das erste GRU-Modell definiert. Als erstes wird ein Input Layer durchlaufen, worauf ein Embedding Layer folgt. Im Anschluss wird ein Stacked GRU-Layer verwendet, dass heißt es werden zwei GRU-Layers hintereinander verwendet. Dieses kann durch diesen Aufbau bessere Modelle trainineren, z.B. ein besseres Verständnis von Grammatikregeln.\n",
    "Danach wird ein Dense Layer für den Output verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_1 = keras.layers.Embedding(input_dim=vocab_size_1, output_dim=embedding_dim_1)(inputs_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(embedding_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(gru_1)\n",
    "outputs_1 = keras.layers.Dense(units=vocab_size_1, activation='softmax')(gru_1)\n",
    "\n",
    "gru_model_1 =  keras.Model(inputs=inputs_1, outputs=outputs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22341a1",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef72809c",
   "metadata": {},
   "source": [
    "Hier werden zum Test die Dimension des ersten Batches as dem Dataset ausgegeben. Die Ausgabe gibt die Batch Size, Sequence Length und die Vocab Size des ersten GRU-Modells an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b412ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch_1, target_example_batch_1 in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_model_1 = gru_model_1(input_example_batch_1)\n",
    "    print(example_batch_predictions_model_1.shape, \"# (batch_size, sequence_length, vocab_size_1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c06e2",
   "metadata": {},
   "source": [
    "Hier wird die Zusammenfassung der wichtigsten Informationen des ersten GRU-Modells angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc713571",
   "metadata": {},
   "source": [
    "Im nächsten Codeblock wird die Zufallsauswahl der Zahlenwerte durch das erste GRU-Modell getestet. Die finale Ausgabe ist das Array mit den Zufallswerten, in dem unnötige Dimensionen entfernt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_gru_model_1 = tf.random.categorical(example_batch_predictions_model_1[0], num_samples=1)\n",
    "sampled_indices_gru_model_1 = tf.squeeze(sampled_indices_gru_model_1, axis=-1).numpy()\n",
    "sampled_indices_gru_model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd25e84",
   "metadata": {},
   "source": [
    "In dem folgenden Code werden die Zahlenwerte des ersten Batches genommen und als Text ausgegeben.\n",
    "Es wird ebenfalls der Text ausgegeben, der durch die Predictions aus dem GRU-Modell 1 erzeugt wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch_1[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296be9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec9d4f",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc07eac",
   "metadata": {},
   "source": [
    "Hier wird die Verlustfunktion definiert. In diesem Fall handelt es sich um Sparse Categorial Crossentropy mit dem Parameter `from_logits` als `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1 = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02fbf53",
   "metadata": {},
   "source": [
    "Hier wird jetzt der Loss auf das GRU-Modell angewendet, indem die Variablen `target_example_batch_1` und `example_batch_predictions_1` als Parameter verwendet werden. Die Ausgabe ist hierzu einmal die Dimensionen des Prediction Modells 1 sowie die Ausgabe des Mean Loss des ersten Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_model_1 = loss_1(target_example_batch_1, example_batch_predictions_model_1)\n",
    "print(\"Prediction shape: \", example_batch_predictions_model_1.shape, \" # (batch_size, sequence_length, vocab_size_1)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0c1b8",
   "metadata": {},
   "source": [
    "Als nächstes wird der Exponentialwert des Mean Loss berechnet. Dieser Sollte in etwa ähnlich zur Vocab Size sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bdf6c",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1431cf",
   "metadata": {},
   "source": [
    "Als nächstes wird das Model kompiliert. Dabei wird der Optimizer `adam`, als Metrik die Accuracy verwendet. Damit es im Ablauf des Trainings keine Fehler gibt, wird der Parameter `run_eagerly` mit dem Wert `True` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.compile(optimizer='adam', loss=loss_1, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7c9de",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914478fc",
   "metadata": {},
   "source": [
    "Hier wird die Early Stopping Callback Funktion für das erste GRU-Modell definiert, damit das Training gestoppt wird, sobald das Modell einen optimalen Wert erreicht hat. Hier wird das Training gestoppt, sobald das Modell sich nicht innerhalb von 2 Epochen um 0,002 verbessert hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4652cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_gru_model_1 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10208b14",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317677f3",
   "metadata": {},
   "source": [
    "Als nächstes wird die Checkpoints Callback definiert, damit nach jeder Epoche die Gew ichtung des Modells gespeichert wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_1'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_1=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032ed9b",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab724ccf",
   "metadata": {},
   "source": [
    "Für das Training wird eine EPOCHS Konstante definiert, hier ist dies 30 Epochen, dass heißt, dass das Modell 30 mal komplett durchlaufen wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_1 = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36deeaa2",
   "metadata": {},
   "source": [
    "Hier wird das erste Modell trainiert. In dem Modell werden das vorher definierte Dataset, die Epochenzahl sowie die Callback Funktionen verwendet. Weiterhin wird für einen späteren Vergleich der Modelle eine Zeitstoppung der gesamten Trainingszeit durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_1_history = gru_model_1.fit(kaggle_dataset, epochs=EPOCHS_1, callbacks=[checkpoint_callback_gru_model_1, early_stopping_gru_model_1])\n",
    "end = time.perf_counter()\n",
    "gru_model_1_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24ea6",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7432b223",
   "metadata": {},
   "source": [
    "Im letzten Schritt für das erste GRU-Modell wird dieses gespeichert, damit es im Notebook für die Textgenerierung verwendet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f10f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.save('work/models/gru_model_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecd01",
   "metadata": {},
   "source": [
    "### 2. GRU-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59cc367",
   "metadata": {},
   "source": [
    "Hier werden wie beim ersten GRU-Modell für das zweite GRU-Modell auch die Vocab Size, die Embedding Dimension sowie die Anzahl der Neuronen festgelegt, diese Anzahl beträgt hier 1024 anstatt der 2048 aus dem ersten Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_2 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_2 = 256\n",
    "rnn_units_2 = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e78c1",
   "metadata": {},
   "source": [
    "Hier wird das zweite GRU-Modell definiert, im Vergleich zum ersten Modell hat dieses zwischen den beiden GRU-Layers eine weitere Schicht. Dies ist das Dropout Layer, dass bewirkt, dass das Modell Overfitting vermeidet, indem 20% der Neuronen auf 0 gesetzt werden. Mit diesem Layer soll das zweite GRU-Layer bessere Ergebnisse erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_2 = keras.layers.Embedding(input_dim=vocab_size_2, output_dim=embedding_dim_2)(inputs_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(embedding_2)\n",
    "dropout_2 = keras.layers.Dropout(0.2)(gru_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(dropout_2)\n",
    "outputs_2 = keras.layers.Dense(units=vocab_size_2, activation='softmax')(gru_2)\n",
    "\n",
    "gru_model_2 = keras.Model(inputs=inputs_2, outputs=outputs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c103cdc",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94520465",
   "metadata": {},
   "source": [
    "Hier wird wie auch beim ersten GRU-Modell das erste Batch des Datasets abgerufen und dessen Dimensionen angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch_2, target_example_batch_2 in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_gru_model_2 = gru_model_2(input_example_batch_2)\n",
    "    print(example_batch_predictions_gru_model_2.shape, \"# (batch_size, sequence_length, vocab_size_2)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fc44b",
   "metadata": {},
   "source": [
    "Der Vorgang ist hier ebenfalls der gleiche wie beim ersten Modell, indem die Zusammenfassung des zweiten GRU-Modells ausgegeben wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66043f",
   "metadata": {},
   "source": [
    "Hier wird wie im ersten GRU-Modell auch die Prediction des Modells getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191298be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_gru_model_2 = tf.random.categorical(example_batch_predictions_gru_model_2[0], num_samples=1)\n",
    "sampled_indices_gru_model_2 = tf.squeeze(sampled_indices_gru_model_2, axis=-1).numpy()\n",
    "sampled_indices_gru_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e01e79",
   "metadata": {},
   "source": [
    "Hier wird wie auch beim ersten GRU-Modell einmal der Text des ersten Batches ausgegeben und die Vorhersage der nächsten Zeichen des zweiten GRU-Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch_2[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f231a1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b7361",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1379b64b",
   "metadata": {},
   "source": [
    "Hier wird die auch beim ersten GRU-Modell die Loss Funktion definiert mit der gleichen Konfiguration wie im ersten Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c46b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_2 = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_model_2 = loss_2(target_example_batch_2, example_batch_predictions_gru_model_2)\n",
    "print(\"Prediction shape: \", example_batch_predictions_gru_model_2.shape, \" # (batch_size, sequence_length, vocab_size_2)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accae874",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e0b17",
   "metadata": {},
   "source": [
    "Hier wird das zweite GRU-Modell kompiliert und dazu werden die gleichen Parameter wie beim ersten GRU-Modell verwendet und die Loss Funktion `loss_2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.compile(optimizer='adam', loss=loss_2, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32b309",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd4164",
   "metadata": {},
   "source": [
    "Als nächstes wird die Early Stopping Callback eingerichtet, diese hat die gleiche Konfiguration wie aus dem ersten GRU-Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_model_2 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f91795",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025c790",
   "metadata": {},
   "source": [
    "Die Checkpoint Callback hat hier die gleiche Konfiguration wie die für das erste GRU-Modell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e4fd0",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cec5a",
   "metadata": {},
   "source": [
    "Das Training des zweiten GRU-Modells wird auch mit 30 Epochen durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1073865",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_2 = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db86691d",
   "metadata": {},
   "source": [
    "Als nächstes wird das Training des zweiten GRU-Modells durchgeführt und die gesamte Trainingszeit gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_2_history = gru_model_2.fit(kaggle_dataset, epochs=EPOCHS_2, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "gru_model_2_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003ce74",
   "metadata": {},
   "source": [
    "### Speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f4c9d1",
   "metadata": {},
   "source": [
    "Das zweite GRU-Modell wird hier gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.save('work/models/gru_model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a13c3",
   "metadata": {},
   "source": [
    "## Bewertung und Vergleich der GRU-Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847509d4",
   "metadata": {},
   "source": [
    "Als nächstes soll ein LSTM-Modell auf der Struktur des besseren GRU-Modell erstellt werden. Damit diese Entscheidung getroffen werden kann, werden die beiden Modelle hier auf Loss, Accuracy, Perplexity und Trainingszeit vergleichen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5326d",
   "metadata": {},
   "source": [
    "### LSTM-Modell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac2423",
   "metadata": {},
   "source": [
    "Da im ersten Durchlauf des Notebooks das erste GRU-Modell die besseren Ergebnisse erzielt hatte, wird dessen Aufbau für die Erstellung des LSTM-Modells verwendet. Dazu wird zum einen die Neuronenanzahl von 2048 verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_lstm = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_lstm = 256\n",
    "rnn_units_lstm = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d95992",
   "metadata": {},
   "source": [
    "Hier wird das LSTM-Modell für den zweiten Teil der Aufgabe erstellt. Da das erste GRU-Modell besser war, wird hier wie in dem ersten GRU-Modell ein Stacked-LSTM-Modell erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_lstm = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_lstm = keras.layers.Embedding(input_dim=vocab_size_lstm, output_dim=embedding_dim_lstm)(inputs_lstm)\n",
    "lstm, hidden_state_1, cell_state_1 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(embedding_lstm)\n",
    "lstm, hidden_state_2, cell_state_2 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(lstm)\n",
    "outputs_lstm = keras.layers.Dense(units=vocab_size_lstm, activation='softmax')(lstm)\n",
    "\n",
    "lstm_model = keras.Model(inputs=inputs_lstm, outputs=outputs_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4631e9b",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b61c8",
   "metadata": {},
   "source": [
    "Wie auch in den beiden GRU-Modellen, wird hier für das LSTM-Modell die Dimension der Modell Prediction ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch_lstm, target_example_batch_lstm in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_lstm_model = lstm_model(input_example_batch_lstm)\n",
    "    print(example_batch_predictions_lstm_model.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262a87be",
   "metadata": {},
   "source": [
    "Hier wird die Zusammenfassung des LSTM-Modells ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d89caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03462f97",
   "metadata": {},
   "source": [
    "Wie bei den beiden ersten Modellen wird hier für das LSTM-Modell die Prediction des Modells zum Test ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6550e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_lstm_model = tf.random.categorical(example_batch_predictions_lstm_model[0], num_samples=1)\n",
    "sampled_indices_lstm_model = tf.squeeze(sampled_indices_lstm_model, axis=-1).numpy()\n",
    "sampled_indices_lstm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06079496",
   "metadata": {},
   "source": [
    "Hier gibt es den gleichen Vorgang wie bei den beiden GRU-Modellen: Zuerst wird das erste Input Sample Batch des Datasets ausgegeben, dann wird die Vorhersage der Zeichen des LSTM-Modells ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch_lstm[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_lstm_model).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b71bee",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744bee1",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9979d",
   "metadata": {},
   "source": [
    "Als nächstes wird wie auch bei den GRU-Modellen die Loss Funktion definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_lstm = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41c46f3",
   "metadata": {},
   "source": [
    "Hier wird jetzt der Loss auf das LSTM-Modell angewendet, indem die Variablen `target_example_batch_lstm` und `example_batch_predictions_lstm_model` als Parameter verwendet werden. Die Ausgabe ist hierzu einmal die Dimensionen der Predictions des LSTM-Modell sowie die Ausgabe des Mean Loss des LSTM-Modells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab23fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_lstm_model = loss_lstm(target_example_batch_lstm, example_batch_predictions_lstm_model)\n",
    "print(\"Prediction shape: \", example_batch_predictions_lstm_model.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_lstm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef07c814",
   "metadata": {},
   "source": [
    "Als nächstes wird der Exponentialwert des Mean Loss aus dem LSTM-Modell berechnet. Dieser Sollte in etwa ähnlich zur Vocab Size sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc42d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_lstm_model).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d64682",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1413c73",
   "metadata": {},
   "source": [
    "Hier wird das LSTM-Modell kompiliert und dazu werden die gleichen Parameter wie beim ersten GRU-Modell verwendet und die Loss Funktion `loss_lstm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a83232",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss=loss_lstm, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522cf92",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a120a00",
   "metadata": {},
   "source": [
    "Zum Speichern der Gewichtungen des LSTM-Modells wird hier wie auch bei den GRU-Modellen eine Checkpoint Callback eingerichtet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/lstm_model'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe46cde",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9381006",
   "metadata": {},
   "source": [
    "Die Epochenzahl wird für das Training des LSTM-Modells ebenfalls auf 30 gesetzt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS_LSTM = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251574ad",
   "metadata": {},
   "source": [
    "Das LSTM-Modell wird hier trainiert und dazu wird ebenfalls die Trainingszeit gemessen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "lstm_model_history = lstm_model.fit(kaggle_dataset, epochs=EPOCHS_LSTM, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "lstm_model_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6b41",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd83cf",
   "metadata": {},
   "source": [
    "Das LSTM-Modell wird hier gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('work/models/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e7878",
   "metadata": {},
   "source": [
    "## Vergleich aller Modelle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6578a566",
   "metadata": {},
   "source": [
    "Zum Schluss wird der Vergleich aller drei Modelle angezeigt mit den gleichen Parametern wie auch bei dem Vergleich der beiden GRU-Modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d229ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "loss3 = lstm_model_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "accuracy3 = lstm_model_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "perplexity3 = np.exp(loss3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].plot(loss3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].plot(accuracy3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].plot(perplexity3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(f\" LSTM Model:  {loss3[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(f\" LSTM Model:  {accuracy3[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(f\" LSTM Model:  {perplexity3[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n",
    "print(f\" LSTM Model:  {lstm_model_training_time:2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
