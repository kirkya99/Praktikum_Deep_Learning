{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ff7c47",
   "metadata": {},
   "source": [
    "# Finale Aufgabe für Praktikum Deep Learning <br>Textgenerierung mit RNN: Modelltraining\n",
    "\n",
    "* **Name:** Fabian Schotte\n",
    "* **Email:** fabian.schotte@rwu.de\n",
    "* **Matrikelnummer:** 35604\n",
    "* **Studiengang:** Angewandte Informatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cb461a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 20:56:53.369558: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-24 20:56:53.376902: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750798613.385529     560 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750798613.388140     560 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-24 20:56:53.396909: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from work import models\n",
    "import time \n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc877b",
   "metadata": {},
   "source": [
    "## Vorbereitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b982723",
   "metadata": {},
   "source": [
    "### Laden der Trainingsdaten\n",
    "Hier werden die Trainings- und Testdaten der Kaggle Sentiment Analyis aus deren CSV-Dateien ausgelesen und die Inhalte der Spalte `text` zu dem String `kaggle_text` zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I`d have responded, if I were going\n",
      " Sooo SAD I will miss you here in San Diego!!!\n",
      "my boss is bullying me...\n",
      " what interview! leave me alone\n",
      " Sons of ****, why couldn`t they put them on the releases we already bought\n",
      "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
      "2am feedings for the baby are fun when he is all smiles and coos\n",
      "Soooo high\n",
      " Both of you\n",
      " Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\n",
      " as much as i love to be hopef\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_test.csv', encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "kaggle_text_train = df_train['text'].str.cat(sep='\\n')\n",
    "kaggle_text_test = df_test['text'].str.cat(sep='\\n')\n",
    "# kaggle_text = kaggle_text_train + '\\n' + kaggle_text_test\n",
    "kaggle_text = kaggle_text_train\n",
    "# kaggle_text = kaggle_text_test\n",
    "\n",
    "print(kaggle_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b972c94",
   "metadata": {},
   "source": [
    "Im nächsten Codeblock wird ein Set der einzigartigen Charaktere im String `kaggle_text` mit dem Namen `vocab` erstellt. Ebenso werden die darin vorhandenen Charaktere ausgegeben und die Länge des Sets ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e74c7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', '´', '½', '¿', 'Â', 'ï']\n",
      "vocab size = 102\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(kaggle_text))\n",
    "print(vocab)\n",
    "print(f\"vocab size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ee022",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Im folgenden Codeblock wird ein Beispieltext zu einer Liste von Charakteren aufgeteilt und ausgegeben. Diese List wird als `chars` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21db466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750798615.429478     560 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9397 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd'],\n",
       " [b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd']]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['hello world', 'hello world']\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c60104",
   "metadata": {},
   "source": [
    "In der Funktion `ids_from_chars` werden die gegebenen Charaktere in eine zugeordnete Zahl für das Training und die Vorhersage umgewandelt.\n",
    "Die Funktion `chars_from_ids` funktioniert genau umgekehrt, indem hier die gegebenen Zahlen in die dazugehörigen Charaktere umgewandelt werden.\n",
    "Hier werden auch die beiden Methoden für den Beispieltext aus `chars` durchgeführt und ausgegeben. Zur Vollständigkeit werden die Charaktere, die aus den Zahlenwerten generiert wurden, wieder zu einem String zusammengefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6db8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[74, 71, 78, 78, 81, 3, 89, 81, 84, 78, 70],\n",
      " [74, 71, 78, 78, 81, 3, 89, 81, 84, 78, 70]]>\n",
      "<tf.RaggedTensor [[b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd'],\n",
      " [b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd']]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'hello world', b'hello world'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_from_chars = keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "print(ids)\n",
    "\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)\n",
    "print(chars)\n",
    "\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd5b17",
   "metadata": {},
   "source": [
    "In `text_from_ids(ids)` wird genau die Operation für das Zusammenfügen der Charaktere zu einem String ausgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae684c0",
   "metadata": {},
   "source": [
    "Hier wird die zuvor genannte Funktion zur Berechnung der Zahlenwerte aus den Charakteren `kaggle_text` verwendet, um die Trainingsdaten als Zahlenwerte zu erhalten. Diese werden in `all_ids` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2463304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1905188,), dtype=int64, numpy=array([ 3, 43, 66, ..., 85, 11, 11])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(kaggle_text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d7080",
   "metadata": {},
   "source": [
    "Als nächstes wird ein Dataset aus den Zahlenwerten generiert. Die ersten 10 Werte des Datasets werden als Charaktere ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c811c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I\n",
      "`\n",
      "d\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 20:56:56.329995: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99eea65",
   "metadata": {},
   "source": [
    "Mit `seq_lenth` wird die Länge der Sequenz definiert, mit dem die Modelle trainiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4a270a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5169f2",
   "metadata": {},
   "source": [
    "Im nächsten Schritt werden die Sequenzen mit Hilfe von `seq_lenth` generiert. Die Daten für die Sequenzeb kommen aus dem zuvor angelegten Dataset `ids_dataset`.\n",
    "Dazu werden auch die Charaktere der ersten Sequenz zuerst einzeln und dann als Text ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce1c8fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b' ' b'I' b'`' b'd' b' ' b'h' b'a' b'v' b'e' b' ' b'r' b'e' b's' b'p'\n",
      " b'o' b'n' b'd' b'e' b'd' b',' b' ' b'i' b'f' b' ' b'I' b' ' b'w' b'e'\n",
      " b'r' b'e' b' ' b'g' b'o' b'i' b'n' b'g' b'\\n' b' ' b'S' b'o' b'o' b'o'\n",
      " b' ' b'S' b'A' b'D' b' ' b'I' b' ' b'w' b'i' b'l' b'l' b' ' b'm' b'i'\n",
      " b's' b's' b' ' b'y' b'o' b'u' b' ' b'h' b'e' b'r' b'e' b' ' b'i' b'n'\n",
      " b' ' b'S' b'a' b'n' b' ' b'D' b'i' b'e' b'g' b'o' b'!' b'!' b'!' b'\\n'\n",
      " b'm' b'y' b' ' b'b' b'o' b's' b's' b' ' b'i' b's' b' ' b'b' b'u' b'l'\n",
      " b'l' b'y' b'i']\n",
      "b' I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bullyi'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 20:56:56.426928: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq).numpy())\n",
    "for seq in sequences.take(1):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905968c",
   "metadata": {},
   "source": [
    "In `split_input_target(sequence)` werden die Inputs und Target Labels der Sequenz generiert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "323da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ea2d1b",
   "metadata": {},
   "source": [
    "Im folgenden Code wird die zuvor erstellte Methode `split_input_target` auf die Sequenzen der Kaggle Trainingsdaten angewendet und die Länge des Datasets ausgegeben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87752867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18863"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kaggle_dataset = sequences.map(split_input_target)\n",
    "len(kaggle_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aa96a1",
   "metadata": {},
   "source": [
    "Als nächstes werden Beispiele für die Input und Labels als Text und mit dessen Shape ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15082ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: b' I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bully'\n",
      "Target: b'I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bullyi'\n",
      "Input shape: (100,)\n",
      "Target shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 20:56:56.603954: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in kaggle_dataset.take(1):\n",
    "    print(\"Input:\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af338f6",
   "metadata": {},
   "source": [
    "Als nächstes werden folgende Variablen für das Training definiert:\n",
    "- Mit `BATCH_SIZE` wird definiert, wie viele Input-Label-Paare in einer Epoche verarbeitet werden. Hier sind dies 150\n",
    "- Mit `BUFFER_SIZE` wird die Anzahl der Elemente des Datasets definiert, die zufällig gemischt werden, bevor sie in die Batches eingeteilt werden.\n",
    "\n",
    "Dieses Variablen werden hier auch auf das Dataset `kaggle_dataset` angewendet und dieses Dataset wird ebenfalls ausgegeben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07fcb3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(150, 100), dtype=tf.int64, name=None), TensorSpec(shape=(150, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 150\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "kaggle_dataset = (\n",
    "    kaggle_dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "kaggle_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841381c6",
   "metadata": {},
   "source": [
    "### 1. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69bd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_1 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_1 = 256\n",
    "rnn_units_1 = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e96b3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_1 = keras.layers.Embedding(input_dim=vocab_size_1, output_dim=embedding_dim_1)(inputs_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(embedding_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(gru_1)\n",
    "outputs_1 = keras.layers.Dense(units=vocab_size_1, activation='softmax')(gru_1)\n",
    "\n",
    "gru_model_1 =  keras.Model(inputs=inputs_1, outputs=outputs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22341a1",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b412ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750798623.455405     698 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 100, 103) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_model_1 = gru_model_1(input_example_batch)\n",
    "    print(example_batch_predictions_model_1.shape, \"# (batch_size, sequence_length, vocab_size_1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b2b294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,168,064</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,178,112</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">211,047</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m26,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m14,168,064\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m25,178,112\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)      │       \u001b[38;5;34m211,047\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c9ad158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 99,  68,  57,  59,  32,  66,  12, 102,  87,  90,  43,  45,  86,\n",
       "        33,  52,  70,  20,  85,  51,  55,  25,  45,  79,   3,  59,  24,\n",
       "        30,  82,  52,  48,  15,  80,  36,  17,  69,   8,  29,  51,  80,\n",
       "        48,  82,  50,  40,  88,  57,  68,  63,  63,   0,  45,  60,  77,\n",
       "        67,  58,  40,  51,  50,  24,  53,  89,   7,  77,  33,  18,  50,\n",
       "        23,  92,   6,  10,  31,  63,  34,  90,  82,  40,  86,  82,  61,\n",
       "        96,  18,  70,  97,  40,   8,  18,  44,  28,  19,  26,  25,  81,\n",
       "         3,  79,  64,  85,  36,  25,  19,  55,  21])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices_model_1 = tf.random.categorical(example_batch_predictions_model_1[0], num_samples=1)\n",
    "sampled_indices_model_1 = tf.squeeze(sampled_indices_model_1, axis=-1).numpy()\n",
    "sampled_indices_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230a92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'd Claudia.  Dianne is new to Tweetville, Claudia has been on a while but not active here\\nMy legs are'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'\\xc2\\xbdbWY>`*\\xc3\\xafuxIKt?Rd2sQU7Km Y6<pRN-nB/c&;QnNpPFvWb]][UNK]KZkaXFQP6Sw%k?0P5z$(=]@xpFtp[~0d\\xc2\\xa0F&0J:187o m^sB71U3'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_model_1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296be9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec9d4f",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36f093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e10bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (150, 100, 103)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.634601, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss_model_1 = loss(target_example_batch, example_batch_predictions_model_1)\n",
    "print(\"Prediction shape: \", example_batch_predictions_model_1.shape, \" # (batch_size, sequence_length, vocab_size_1)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa76abe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(102.98683)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bdf6c",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25f161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7c9de",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4652cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_gru_model_1 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10208b14",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a35c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_1'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_1=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032ed9b",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "705b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cc8bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 368ms/step - accuracy: 0.1808 - loss: 3.6047\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 368ms/step - accuracy: 0.3915 - loss: 2.2056\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 358ms/step - accuracy: 0.4879 - loss: 1.8279\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 361ms/step - accuracy: 0.5286 - loss: 1.6605\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 368ms/step - accuracy: 0.5510 - loss: 1.5661\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 363ms/step - accuracy: 0.5701 - loss: 1.4870\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 359ms/step - accuracy: 0.5878 - loss: 1.4152\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 365ms/step - accuracy: 0.6068 - loss: 1.3384\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 370ms/step - accuracy: 0.6288 - loss: 1.2546\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 366ms/step - accuracy: 0.6547 - loss: 1.1589\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 363ms/step - accuracy: 0.6867 - loss: 1.0496\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 364ms/step - accuracy: 0.7216 - loss: 0.9329\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 360ms/step - accuracy: 0.7577 - loss: 0.8143\n",
      "Epoch 14/30\n",
      "\u001b[1m 65/125\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 354ms/step - accuracy: 0.7850 - loss: 0.7202"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_1_history = gru_model_1.fit(kaggle_dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_1, early_stopping_gru_model_1])\n",
    "end = time.perf_counter()\n",
    "gru_model_1_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24ea6",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f10f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.save('work/models/gru_model_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecd01",
   "metadata": {},
   "source": [
    "### 2. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_2 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_2 = 256\n",
    "rnn_units_2 = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_2 = keras.layers.Embedding(input_dim=vocab_size_2, output_dim=embedding_dim_2)(inputs_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(embedding_2)\n",
    "dropout_2 = keras.layers.Dropout(0.2)(gru_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(dropout_2)\n",
    "outputs_2 = keras.layers.Dense(units=vocab_size_2, activation='softmax')(gru_2)\n",
    "\n",
    "gru_model_2 = keras.Model(inputs=inputs_2, outputs=outputs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c103cdc",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_gru_model_2 = gru_model_2(input_example_batch)\n",
    "    print(example_batch_predictions_gru_model_2.shape, \"# (batch_size, sequence_length, vocab_size_2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191298be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_gru_model_2 = tf.random.categorical(example_batch_predictions_gru_model_2[0], num_samples=1)\n",
    "sampled_indices_gru_model_2 = tf.squeeze(sampled_indices_gru_model_2, axis=-1).numpy()\n",
    "sampled_indices_gru_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f231a1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b7361",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c46b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_model_2 = loss(target_example_batch, example_batch_predictions_gru_model_2)\n",
    "print(\"Prediction shape: \", example_batch_predictions_gru_model_2.shape, \" # (batch_size, sequence_length, vocab_size_2)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accae874",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32b309",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_model_2 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f91795",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e4fd0",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1073865",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_2_history = gru_model_2.fit(kaggle_dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "gru_model_2_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003ce74",
   "metadata": {},
   "source": [
    "### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.save('work/models/gru_model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a13c3",
   "metadata": {},
   "source": [
    "## Bewertung und Vergleich der GRU-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5326d",
   "metadata": {},
   "source": [
    "### LSTM-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_lstm = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_lstm = 256\n",
    "rnn_units_lstm = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_lstm = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_lstm = keras.layers.Embedding(input_dim=vocab_size_lstm, output_dim=embedding_dim_lstm)(inputs_lstm)\n",
    "lstm, hidden_state_1, cell_state_1 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(embedding_lstm)\n",
    "lstm, hidden_state_2, cell_state_2 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(lstm)\n",
    "outputs_lstm = keras.layers.Dense(units=vocab_size, activation='softmax')(lstm)\n",
    "\n",
    "lstm_model = keras.Model(inputs=inputs_lstm, outputs=outputs_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4631e9b",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in kaggle_dataset.take(1):\n",
    "    example_batch_predictions_lstm_model = lstm_model(input_example_batch)\n",
    "    print(example_batch_predictions_lstm_model.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d89caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6550e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_lstm_model = tf.random.categorical(example_batch_predictions_lstm_model[0], num_samples=1)\n",
    "sampled_indices_lstm_model = tf.squeeze(sampled_indices_lstm_model, axis=-1).numpy()\n",
    "sampled_indices_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b71bee",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744bee1",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab23fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_lstm_model = loss(target_example_batch, example_batch_predictions_lstm_model)\n",
    "print(\"Prediction shape: \", example_batch_predictions_lstm_model.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc42d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_lstm_model).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d64682",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a83232",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522cf92",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/lstm_model'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe46cde",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "lstm_model_history = lstm_model.fit(kaggle_dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "lstm_model_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6b41",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('work/models/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e7878",
   "metadata": {},
   "source": [
    "## Vergleich aller Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d229ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "loss3 = lstm_model_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "accuracy3 = lstm_model_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "perplexity3 = np.exp(loss3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].plot(loss3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].plot(accuracy3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].plot(perplexity3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(f\" LSTM Model:  {loss3[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(f\" LSTM Model:  {accuracy3[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(f\" LSTM Model:  {perplexity3[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n",
    "print(f\" LSTM Model:  {lstm_model_training_time:2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
