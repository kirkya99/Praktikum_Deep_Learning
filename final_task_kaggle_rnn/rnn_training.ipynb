{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ff7c47",
   "metadata": {},
   "source": [
    "# Finale Aufgabe für Praktikum Deep Learning <br>Textgenerierung mit RNN: Modelltraining\n",
    "\n",
    "* **Name:** Fabian Schotte\n",
    "* **Email:** fabian.schotte@rwu.de\n",
    "* **Matrikelnummer:** 35604\n",
    "* **Studiengang:** Angewandte Informatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb461a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from work import models\n",
    "import time \n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc877b",
   "metadata": {},
   "source": [
    "## Vorbereitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b982723",
   "metadata": {},
   "source": [
    "### Laden der Trainingsdaten\n",
    "Hier werden die Trainings- und Testdaten der Kaggle Sentiment Analyis aus deren CSV-Dateien ausgelesen und die Inhalte der Spalte `text` zu dem String `kaggle_text` zusammengefasst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I`d have responded, if I were going\n",
      " Sooo SAD I will miss you here in San Diego!!!\n",
      "my boss is bullying me...\n",
      " what interview! leave me alone\n",
      " Sons of ****, why couldn`t they put them on the releases we already bought\n",
      "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
      "2am feedings for the baby are fun when he is all smiles and coos\n",
      "Soooo high\n",
      " Both of you\n",
      " Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\n",
      " as much as i love to be hopef\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_test.csv', encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "kaggle_text_train = df_train['text'].str.cat(sep='\\n')\n",
    "kaggle_text_test = df_test['text'].str.cat(sep='\\n')\n",
    "# kaggle_text = kaggle_text_train + '\\n' + kaggle_text_test\n",
    "kaggle_text = kaggle_text_train\n",
    "# kaggle_text = kaggle_text_test\n",
    "\n",
    "print(kaggle_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b972c94",
   "metadata": {},
   "source": [
    "Im nächsten Codeblock wird ein Set der einzigartigen Charaktere im String `kaggle_text` mit dem Namen `vocab` erstellt. Ebenso werden die darin vorhandenen Charaktere ausgegeben und die Länge des Sets ausgegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e74c7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', '´', '½', '¿', 'Â', 'ï']\n",
      "vocab size = 102\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(kaggle_text))\n",
    "print(vocab)\n",
    "print(f\"vocab size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ee022",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Im folgenden Codeblock wird ein Beispieltext zu einer Liste von Charakteren aufgeteilt und ausgegeben. Diese List wird als `chars` gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21db466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd'],\n",
       " [b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd']]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['hello world', 'hello world']\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c60104",
   "metadata": {},
   "source": [
    "Hier werden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6db8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[74, 71, 78, 78, 81, 3, 89, 81, 84, 78, 70],\n",
      " [74, 71, 78, 78, 81, 3, 89, 81, 84, 78, 70]]>\n",
      "<tf.RaggedTensor [[b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd'],\n",
      " [b'h', b'e', b'l', b'l', b'o', b' ', b'w', b'o', b'r', b'l', b'd']]>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([b'hello world', b'hello world'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_from_chars = keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "ids = ids_from_chars(chars)\n",
    "print(ids)\n",
    "\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "chars = chars_from_ids(ids)\n",
    "print(chars)\n",
    "\n",
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(kaggle_text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c811c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a270a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq).numpy())\n",
    "for seq in sequences.take(1):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87752867",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15082ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input:\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 150\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba2c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim = 256\n",
    "rnn_units = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841381c6",
   "metadata": {},
   "source": [
    "### 1. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bd304",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_1 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_1 = 256\n",
    "rnn_units_1 = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_1 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_1 = keras.layers.Embedding(input_dim=vocab_size_1, output_dim=embedding_dim_1)(inputs_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(embedding_1)\n",
    "gru_1, gru_state_1 = keras.layers.GRU(units=rnn_units_1, return_sequences=True, return_state=True)(gru_1)\n",
    "outputs_1 = keras.layers.Dense(units=vocab_size, activation='softmax')(gru_1)\n",
    "\n",
    "gru_model_1 =  keras.Model(inputs=inputs_1, outputs=outputs_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22341a1",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b412ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions_model_1 = gru_model_1(input_example_batch)\n",
    "    print(example_batch_predictions_model_1.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b2b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9ad158",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_model_1 = tf.random.categorical(example_batch_predictions_model_1[0], num_samples=1)\n",
    "sampled_indices_model_1 = tf.squeeze(sampled_indices_model_1, axis=-1).numpy()\n",
    "sampled_indices_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_model_1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296be9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec9d4f",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e10bf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_model_1 = loss(target_example_batch, example_batch_predictions_model_1)\n",
    "print(\"Prediction shape: \", example_batch_predictions_model_1.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa76abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bdf6c",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7c9de",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4652cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_gru_model_1 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10208b14",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_1'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_1=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032ed9b",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_1_history = gru_model_1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_1, early_stopping_gru_model_1])\n",
    "end = time.perf_counter()\n",
    "gru_model_1_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24ea6",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f10f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.save('work/models/gru_model_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecd01",
   "metadata": {},
   "source": [
    "### 2. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_2 = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_2 = 256\n",
    "rnn_units_2 = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c047b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_2 = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_2 = keras.layers.Embedding(input_dim=vocab_size_2, output_dim=embedding_dim_2)(inputs_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(embedding_2)\n",
    "dropout_2 = keras.layers.Dropout(0.2)(gru_2)\n",
    "gru_2, gru_state_2 = keras.layers.GRU(units=rnn_units_2, return_sequences=True, return_state=True)(dropout_2)\n",
    "outputs_2 = keras.layers.Dense(units=vocab_size, activation='softmax')(gru_2)\n",
    "\n",
    "gru_model_2 = keras.Model(inputs=inputs_2, outputs=outputs_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c103cdc",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd13b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions_gru_model_2 = gru_model_2(input_example_batch)\n",
    "    print(example_batch_predictions_gru_model_2.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9acd0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191298be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_gru_model_2 = tf.random.categorical(example_batch_predictions_gru_model_2[0], num_samples=1)\n",
    "sampled_indices_gru_model_2 = tf.squeeze(sampled_indices_gru_model_2, axis=-1).numpy()\n",
    "sampled_indices_gru_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442dfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f231a1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b7361",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c46b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_model_2 = loss(target_example_batch, example_batch_predictions_gru_model_2)\n",
    "print(\"Prediction shape: \", example_batch_predictions_gru_model_2.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0f69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accae874",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32b309",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_model_2 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f91795",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e4fd0",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1073865",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a0fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_2_history = gru_model_2.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "gru_model_2_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003ce74",
   "metadata": {},
   "source": [
    "### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.save('work/models/gru_model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a13c3",
   "metadata": {},
   "source": [
    "## Bewertung und Vergleich der GRU-Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5326d",
   "metadata": {},
   "source": [
    "### LSTM-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5628e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_lstm = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim_lstm = 256\n",
    "rnn_units_lstm = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7e1cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs_lstm = keras.layers.Input(shape=(None,), dtype='int32', name='input_tokens')\n",
    "embedding_lstm = keras.layers.Embedding(input_dim=vocab_size_lstm, output_dim=embedding_dim_lstm)(inputs_lstm)\n",
    "lstm, hidden_state_1, cell_state_1 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(embedding_lstm)\n",
    "lstm, hidden_state_2, cell_state_2 = keras.layers.LSTM(units=rnn_units_lstm, return_sequences=True, return_state=True)(lstm)\n",
    "outputs_lstm = keras.layers.Dense(units=vocab_size, activation='softmax')(lstm)\n",
    "\n",
    "lstm_model = keras.Model(inputs=inputs_lstm, outputs=outputs_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4631e9b",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions_lstm_model = lstm_model(input_example_batch)\n",
    "    print(example_batch_predictions_lstm_model.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d89caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6550e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices_lstm_model = tf.random.categorical(example_batch_predictions_lstm_model[0], num_samples=1)\n",
    "sampled_indices_lstm_model = tf.squeeze(sampled_indices_lstm_model, axis=-1).numpy()\n",
    "sampled_indices_lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b71bee",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744bee1",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab23fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch_mean_loss_lstm_model = loss(target_example_batch, example_batch_predictions_lstm_model)\n",
    "print(\"Prediction shape: \", example_batch_predictions_lstm_model.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc42d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.exp(example_batch_mean_loss_lstm_model).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d64682",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a83232",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522cf92",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/lstm_model'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe46cde",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f6cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fbbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "lstm_model_history = lstm_model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_2, early_stopping_model_2])\n",
    "end = time.perf_counter()\n",
    "lstm_model_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6b41",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801f494",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.save('work/models/lstm_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e7878",
   "metadata": {},
   "source": [
    "## Vergleich aller Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d229ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "loss3 = lstm_model_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "accuracy3 = lstm_model_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "perplexity3 = np.exp(loss3)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].plot(loss3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].plot(accuracy3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].plot(perplexity3, label=\"LSTM Model\", linestyle='-', color='green')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "print(\"Loss:\")\n",
    "print(f\" GRU Model 1: {loss1[-1]}\")\n",
    "print(f\" GRU Model 2: {loss2[-1]}\")\n",
    "print(f\" LSTM Model:  {loss3[-1]}\")\n",
    "print(\"Accuracy:\")\n",
    "print(f\" GRU Model 1: {accuracy1[-1]}\")\n",
    "print(f\" GRU Model 2: {accuracy2[-1]}\")\n",
    "print(f\" LSTM Model:  {accuracy3[-1]}\")\n",
    "print(\"Perplexity:\")\n",
    "print(f\" GRU Model 1: {perplexity1[-1]}\")\n",
    "print(f\" GRU Model 2: {perplexity2[-1]}\")\n",
    "print(f\" LSTM Model:  {perplexity3[-1]}\")\n",
    "print(\"Training Times:\")\n",
    "print(f\" GRU Model 1: {gru_model_1_training_time:2f}s\")\n",
    "print(f\" GRU Model 2: {gru_model_2_training_time:2f}s\")\n",
    "print(f\" LSTM Model:  {lstm_model_training_time:2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
