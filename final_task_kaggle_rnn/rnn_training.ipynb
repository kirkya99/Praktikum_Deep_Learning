{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14ff7c47",
   "metadata": {},
   "source": [
    "# Finale Aufgabe für Praktikum Deep Learning <br>Textgenerierung mit RNN: Modelltraining\n",
    "\n",
    "* **Name:** Fabian Schotte\n",
    "* **Email:** fabian.schotte@rwu.de\n",
    "* **Matrikelnummer:** 35604\n",
    "* **Studiengang:** Angewandte Informatik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb461a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from work import models\n",
    "import time \n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc877b",
   "metadata": {},
   "source": [
    "## Vorbereitung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b982723",
   "metadata": {},
   "source": [
    "### Laden der Trainingsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e1343b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I`d have responded, if I were going\n",
      " Sooo SAD I will miss you here in San Diego!!!\n",
      "my boss is bullying me...\n",
      " what interview! leave me alone\n",
      " Sons of ****, why couldn`t they put them on the releases we already bought\n",
      "http://www.dothebouncy.com/smf - some shameless plugging for the best Rangers forum on earth\n",
      "2am feedings for the baby are fun when he is all smiles and coos\n",
      "Soooo high\n",
      " Both of you\n",
      " Journey!? Wow... u just became cooler.  hehe... (is that possible!?)\n",
      " as much as i love to be hopef\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_train.csv', encoding='utf-8', encoding_errors='replace')\n",
    "df_test = pd.read_csv('work/kaggle_sentiment/tweet_sentiment_test.csv', encoding='utf-8', encoding_errors='replace')\n",
    "\n",
    "kaggle_text_train = df_train['text'].str.cat(sep='\\n')\n",
    "kaggle_text_test = df_test['text'].str.cat(sep='\\n')\n",
    "# kaggle_text = kaggle_text_train + '\\n' + kaggle_text_test\n",
    "kaggle_text = kaggle_text_train\n",
    "# kaggle_text = kaggle_text_test\n",
    "\n",
    "print(kaggle_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e74c7dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\xa0', '´', '½', '¿', 'Â', 'ï']\n",
      "vocab size = 102\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(kaggle_text))\n",
    "print(vocab)\n",
    "print(f\"vocab size = {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ee022",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "21db466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_texts = ['hello world', 'hello world']\n",
    "# chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "# chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e6db8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
    "# ids = ids_from_chars(chars)\n",
    "# print(ids)\n",
    "\n",
    "chars_from_ids = keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
    "# chars = chars_from_ids(ids)\n",
    "# print(chars)\n",
    "\n",
    "# tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "af0b9950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2463304f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1905188,), dtype=int64, numpy=array([ 3, 43, 66, ..., 85, 11, 11])>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(kaggle_text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c811c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "I\n",
      "`\n",
      "d\n",
      " \n",
      "h\n",
      "a\n",
      "v\n",
      "e\n",
      " \n"
     ]
    }
   ],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n",
    "\n",
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f4a270a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ce1c8fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b' ' b'I' b'`' b'd' b' ' b'h' b'a' b'v' b'e' b' ' b'r' b'e' b's' b'p'\n",
      " b'o' b'n' b'd' b'e' b'd' b',' b' ' b'i' b'f' b' ' b'I' b' ' b'w' b'e'\n",
      " b'r' b'e' b' ' b'g' b'o' b'i' b'n' b'g' b'\\n' b' ' b'S' b'o' b'o' b'o'\n",
      " b' ' b'S' b'A' b'D' b' ' b'I' b' ' b'w' b'i' b'l' b'l' b' ' b'm' b'i'\n",
      " b's' b's' b' ' b'y' b'o' b'u' b' ' b'h' b'e' b'r' b'e' b' ' b'i' b'n'\n",
      " b' ' b'S' b'a' b'n' b' ' b'D' b'i' b'e' b'g' b'o' b'!' b'!' b'!' b'\\n'\n",
      " b'm' b'y' b' ' b'b' b'o' b's' b's' b' ' b'i' b's' b' ' b'b' b'u' b'l'\n",
      " b'l' b'y' b'i']\n",
      "b' I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bullyi'\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length + 1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq).numpy())\n",
    "for seq in sequences.take(1):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "323da8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4340e8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "87752867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18863"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sequences.map(split_input_target)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "15082ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: b' I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bully'\n",
      "Target: b'I`d have responded, if I were going\\n Sooo SAD I will miss you here in San Diego!!!\\nmy boss is bullyi'\n",
      "Input shape: (100,)\n",
      "Target shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input:\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())\n",
    "    print(\"Input shape:\", input_example.shape)\n",
    "    print(\"Target shape:\", target_example.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "07fcb3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(150, 100), dtype=tf.int64, name=None), TensorSpec(shape=(150, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 150\n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed620d5",
   "metadata": {},
   "source": [
    "## RNN-Modelle\n",
    "### Variablen für Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2ba2c8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(ids_from_chars.get_vocabulary())\n",
    "embedding_dim = 256\n",
    "rnn_units = 2048"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841381c6",
   "metadata": {},
   "source": [
    "### 1. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e96b3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1 = models.get_gru_model_1(vocab_size, embedding_dim, rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22341a1",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2b412ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 100, 103) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions_model_1 = gru_model_1(input_example_batch)\n",
    "    print(example_batch_predictions_model_1.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d4b2b294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,168,064</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,178,112</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">211,047</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m26,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_8 (\u001b[38;5;33mGRU\u001b[0m)                     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m14,168,064\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_9 (\u001b[38;5;33mGRU\u001b[0m)                     │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m25,178,112\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)      │       \u001b[38;5;34m211,047\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4c9ad158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13,  26,  15,  28,  20,  95,  60,  17,  49,  84,  78,  67,  62,\n",
       "        24,  26,  92,  58,  13,  59,  17,  34,   3,  99,  29,  38,  91,\n",
       "        19,  71,  75,  42,  49,  86,   0,  38,  55,  28,  42,  36,  16,\n",
       "        30,   6,  65,  85,  82,   4,  77,  57,   0,  41,  90,  10,  51,\n",
       "        84,  47,  84,  78,  97,  45,  49, 101,  74,   2,  62,  11,  97,\n",
       "        93,  48,  52,  46,  83,  98,  57, 102,  74,  53,  87,  32,  62,\n",
       "        39, 101,  83,  62,  97,  10,  75,  70,  30,  18,  26,  97,  65,\n",
       "        38,  56,  86,  14,  54,  14,  98,  72,   7])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices_model_1 = tf.random.categorical(example_batch_predictions_model_1[0], num_samples=1)\n",
    "sampled_indices_model_1 = tf.squeeze(sampled_indices_model_1, axis=-1).numpy()\n",
    "sampled_indices_model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "230a92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b't sit down through the whole thing  mcfly did you see me and ma best mate we were in tutus\\n2 days wi'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'+8-:2}Z/Orla\\\\68zX+Y/@ \\xc2\\xbd;Dy1eiHOt[UNK]DU:HB.<$_sp!kW[UNK]Gx(QrMrl\\xc2\\xa0KO\\xc3\\x82h\\n\\\\)\\xc2\\xa0{NRLq\\xc2\\xb4W\\xc3\\xafhSu>\\\\E\\xc3\\x82q\\\\\\xc2\\xa0(id<08\\xc2\\xa0_DVt,T,\\xc2\\xb4f%'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_model_1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4296be9c",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ec9d4f",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "36f093d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4e10bf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (150, 100, 103)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.634127, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:708: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss_model_1 = loss(target_example_batch, example_batch_predictions_model_1)\n",
    "print(\"Prediction shape: \", example_batch_predictions_model_1.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "fa76abe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(102.938034)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1bdf6c",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "25f161a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7c9de",
   "metadata": {},
   "source": [
    "##### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b4652cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_gru_model_1 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10208b14",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7a35c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_1'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_1=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032ed9b",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "705b9dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc8bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.1883 - loss: 3.5488\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.3953 - loss: 2.1911\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.4892 - loss: 1.8226\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.5288 - loss: 1.6601\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.5521 - loss: 1.5631\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.5712 - loss: 1.4829\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.5886 - loss: 1.4118\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.6081 - loss: 1.3346\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.6304 - loss: 1.2499\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.6569 - loss: 1.1526\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.6882 - loss: 1.0458\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.7219 - loss: 0.9307\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.7591 - loss: 0.8093\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 254ms/step - accuracy: 0.7924 - loss: 0.6991\n",
      "Epoch 15/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.8227 - loss: 0.5989\n",
      "Epoch 16/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.8473 - loss: 0.5165\n",
      "Epoch 17/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.8664 - loss: 0.4511\n",
      "Epoch 18/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.8798 - loss: 0.4047\n",
      "Epoch 19/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.8895 - loss: 0.3696\n",
      "Epoch 20/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.8957 - loss: 0.3452\n",
      "Epoch 21/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.8997 - loss: 0.3289\n",
      "Epoch 22/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9031 - loss: 0.3156\n",
      "Epoch 23/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.9046 - loss: 0.3077\n",
      "Epoch 24/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 254ms/step - accuracy: 0.9050 - loss: 0.3034\n",
      "Epoch 25/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 251ms/step - accuracy: 0.9038 - loss: 0.3044\n",
      "Epoch 26/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 250ms/step - accuracy: 0.9036 - loss: 0.3031\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_1_history = gru_model_1.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_1, early_stopping_gru_model_1])\n",
    "end = time.perf_counter()\n",
    "gru_model_1_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f24ea6",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b0f10f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_1.save('models/gru_model_1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ecd01",
   "metadata": {},
   "source": [
    "### 2. GRU-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c047b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2 = models.get_gru_model_2(vocab_size, embedding_dim, rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c103cdc",
   "metadata": {},
   "source": [
    "#### Testen des Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0fd13b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 100, 103) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions_gru_model_2 = gru_model_2(input_example_batch)\n",
    "    print(example_batch_predictions_gru_model_2.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "b9acd0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">26,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">14,168,064</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                    │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>),   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">25,178,112</span> │\n",
       "│                                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">103</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">211,047</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_tokens (\u001b[38;5;33mInputLayer\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m26,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_10 (\u001b[38;5;33mGRU\u001b[0m)                    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m14,168,064\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_11 (\u001b[38;5;33mGRU\u001b[0m)                    │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m),   │    \u001b[38;5;34m25,178,112\u001b[0m │\n",
       "│                                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)]          │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m103\u001b[0m)      │       \u001b[38;5;34m211,047\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">39,583,591</span> (151.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m39,583,591\u001b[0m (151.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "191298be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 45, 102,  59,  94,  42,  23,  77,  91,  76,  80,  40,  61,  52,\n",
       "         8, 102,  90,  63,   3,  75,  57,  90, 102,  80,  23,   2,  79,\n",
       "        94,  97,  74,  85,  68,  13,  40,  72,  96,  23,  65,   5,  61,\n",
       "        65,  61,  59,  64,  47,  64,  57,  98,  64,  59,  92,  62,  87,\n",
       "        20,  41,  52,  70,  76,  81,  47,  13,  76,   8,  14,  39,  33,\n",
       "        20,  73,  11,   3,  60,  29,   0,  82,  85,  64,  87,  20,  34,\n",
       "        51,  15,  10,  71,  83,  92,  20,  13,  87,  90,  38,  92,   5,\n",
       "        60,  98,  40, 100,  79,  36,  90,  85,  77])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices_gru_model_2 = tf.random.categorical(example_batch_predictions_gru_model_2[0], num_samples=1)\n",
    "sampled_indices_gru_model_2 = tf.squeeze(sampled_indices_gru_model_2, axis=-1).numpy()\n",
    "sampled_indices_gru_model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d442dfd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'your race photos to runners\\nGoodmorning twitter, oh my gosh, i woke up soooo nice, lol ... oh hai th'\n",
      "\n",
      "Next Char Predictions:\n",
      " b'K\\xc3\\xafY|H5kyjnF[R&\\xc3\\xafx] iWx\\xc3\\xafn5\\nm|\\xc2\\xa0hsb+Ff~5_#[_[Y^M^W\\xc2\\xb4^Yz\\\\u2GRdjoM+j&,E?2g) Z;[UNK]ps^u2@Q-(eqz2+uxDz#Z\\xc2\\xb4F\\xc2\\xbfmBxsk'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices_gru_model_2).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f231a1",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b7361",
   "metadata": {},
   "source": [
    "#### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d2c46b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "690a750c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (150, 100, 103)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         tf.Tensor(4.6353617, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "example_batch_mean_loss_model_2 = loss(target_example_batch, example_batch_predictions_gru_model_2)\n",
    "print(\"Prediction shape: \", example_batch_predictions_gru_model_2.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", example_batch_mean_loss_model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cae0f69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(102.938034)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(example_batch_mean_loss_model_1).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accae874",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "63c65364",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.compile(optimizer='adam', loss=loss, metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32b309",
   "metadata": {},
   "source": [
    "##### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "6c43a8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_gru_model_2 = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0.002, patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f91795",
   "metadata": {},
   "source": [
    "#### Konfiguration von Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "5d2432ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './work/training_checkpoints/gru_model_2'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
    "\n",
    "checkpoint_callback_gru_model_2=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065e4fd0",
   "metadata": {},
   "source": [
    "#### Ausführen des Trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a1073865",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a0fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.1830 - loss: 3.5651\n",
      "Epoch 2/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 251ms/step - accuracy: 0.3903 - loss: 2.2093\n",
      "Epoch 3/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.4868 - loss: 1.8306\n",
      "Epoch 4/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 253ms/step - accuracy: 0.5273 - loss: 1.6671\n",
      "Epoch 5/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.5501 - loss: 1.5720\n",
      "Epoch 6/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.5679 - loss: 1.4959\n",
      "Epoch 7/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 255ms/step - accuracy: 0.5845 - loss: 1.4266\n",
      "Epoch 8/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.6024 - loss: 1.3566\n",
      "Epoch 9/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.6208 - loss: 1.2842\n",
      "Epoch 10/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 252ms/step - accuracy: 0.6405 - loss: 1.2088\n",
      "Epoch 11/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.6634 - loss: 1.1272\n",
      "Epoch 12/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 247ms/step - accuracy: 0.6875 - loss: 1.0426\n",
      "Epoch 13/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.7099 - loss: 0.9629\n",
      "Epoch 14/30\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 249ms/step - accuracy: 0.7320 - loss: 0.8858\n",
      "Epoch 15/30\n",
      "\u001b[1m 54/125\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 252ms/step - accuracy: 0.7480 - loss: 0.8293"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "gru_model_2_history = gru_model_2.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback_gru_model_2, early_stopping_gru_model_2])\n",
    "end = time.perf_counter()\n",
    "gru_model_2_training_time = end - start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a003ce74",
   "metadata": {},
   "source": [
    "#### Speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model_2.save('models/gru_model_2.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a13c3",
   "metadata": {},
   "source": [
    "## Vergleich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = gru_model_1_history.history['loss']\n",
    "loss2 = gru_model_2_history.history['loss']\n",
    "\n",
    "accuracy1 = gru_model_1_history.history['accuracy']\n",
    "accuracy2 = gru_model_2_history.history['accuracy']\n",
    "\n",
    "perplexity1 = np.exp(loss1)\n",
    "perplexity2 = np.exp(loss2)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4)) \n",
    "\n",
    "axes[0].plot(loss1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[0].plot(loss2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[0].set_xlabel(\"Epochs\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Comparison of Training Histories\")\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(accuracy1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[1].plot(accuracy2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[1].set_xlabel(\"Epochs\")\n",
    "axes[1].set_ylabel(\"Accuracy\")\n",
    "axes[1].set_title(\"Accuracy Comparison\")\n",
    "axes[1].legend()\n",
    "\n",
    "axes[2].plot(perplexity1, label=\"GRU Model 1\", linestyle='-', color='blue')\n",
    "axes[2].plot(perplexity2, label=\"GRU Model 2\", linestyle='-', color='red')\n",
    "axes[2].set_xlabel(\"Epochs\")\n",
    "axes[2].set_ylabel(\"Perplexity\")\n",
    "axes[2].set_title(\"Perplexity Comparison\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e8e5a",
   "metadata": {},
   "source": [
    "## LSTM-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6f0d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
